import streamlit as st
import faiss
import pandas as pd

from src.helper import semantic_similarity, call_llm

#function to display the response and handle feedback
def display_response(query, df, index):
    #call the semantic_similarity function to get the most similar instructions using the query
    distances, indices = semantic_similarity(query, index, model='text-embedding-3-small')

    #search the original dataframe for the similar instructions and pass it to a new dataframe 
    top_similar_instructions = df.iloc[indices[0]].reset_index(drop=True)
    top_similar_instructions['distance'] = distances[0]
    
    #display the similar responses from the internal dataset
    st.write("Responses from the internal dataset")
    st.write(top_similar_instructions[['instruction', 'intent', 'response']])

    #display the response generated by LLM according to prompt in helper.py
    
    st.write(f"Following responses will be generated:\n"
            "1. Urgency of the query based on the input query on a scale of 1-5 where 1 is least urgent and 5 is most urgent.\n"
            "2. Categorize the input query into sales, product, operations etc.\n"
            "3. Generated Response from LLM.")
    st.write("## Response from LLM below (wait a few seconds)")
    llm_response = call_llm(query, top_similar_instructions['response'].tolist())
    st.write(llm_response)

    return llm_response, top_similar_instructions


st.title("AI Assisted Customer Support")

#input query from the customer
query = st.text_input("Inbound query:", key="query")

#load the created vector DB and the dataset for the RAG
index = faiss.read_index('vector_store/faiss_index.index')
df = pd.read_csv('Customer_Support_Training_Dataset/Customer_Support_Training_Dataset.csv')

if st.button("Get response from internal dataset and Run LLM"):
    if not query:
        st.error("Please enter a query.")
    else:
        #call the display_response function to get the LLM response and similar instructions
        llm_response, top_similar_instructions = display_response(query, df, index)
        
        #store the LLM response and similar instructions in session state
        st.session_state['llm_response'] = llm_response
        st.session_state['top_similar_instructions'] = top_similar_instructions

#check if LLM response is stored in session state
if 'llm_response' in st.session_state:
    llm_response = st.session_state['llm_response']
    top_similar_instructions = st.session_state['top_similar_instructions']

    #add feedback section
    st.write("## Feedback")
    feedback = st.text_area("Provide feedback or additional instructions for the response:", key="feedback")
    
    if st.button("Accept Response"):
        st.success("Response has been submitted.")
    
    if st.button("Regenerate Response"):
        if feedback:
            #generate a new query for LLM based on the feedback
            new_query = f'''Regenerate third point of this response: {llm_response}.\n 
                    You must only regenerate third point according to the feedback later. Do not change 1st and 2nd point at any cost but always have them in the final output.\n Feedback: {feedback}'''
            print(new_query)
            
            #call LLM with the new query and get the regenerated response
            new_llm_response = call_llm(new_query, top_similar_instructions['response'].tolist())
            
            #display the new LLM response
            st.write("## New Response from LLM (wait a few seconds)")
            st.write(new_llm_response)
            
            #update the LLM response in session state
            st.session_state['llm_response'] = new_llm_response
        else:
            st.error("Please provide feedback to regenerate the response.")